{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "5ad08ec8-783b-4fd5-86a0-b269b5e0118d",
    "deletable": false
   },
   "source": [
    "# Homework 3 -- Neural models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "005ead6f-ac5a-4681-8c5e-d8d16473409f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "num_threads = 1  # if you change this number you have to restart the notebook\n",
    "\n",
    "# A hyperparameter for the size of all the hidden layers throughout the notebook.\n",
    "HIDDEN_SIZE = 30\n",
    "\n",
    "# set this before we import numpy\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_threads)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import logsumexp\n",
    "import sys\n",
    "import re\n",
    "from itertools import islice\n",
    "from pprint import pprint\n",
    "import math\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor, FloatTensor, LongTensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def var(val):\n",
    "    return Variable(torch.FloatTensor(val), requires_grad=True)\n",
    "\n",
    "torch.set_num_threads(num_threads)\n",
    "\n",
    "\n",
    "from seq2class_homework1 import (\n",
    "    TaskSetting,\n",
    "    ProbabilityModel,\n",
    "    BoltzmannModel,\n",
    "    DecisionAgent,\n",
    "    ViterbiAgent,\n",
    "    BayesAgent,\n",
    "    L2LogLikelihood,\n",
    "    SGDTrainer\n",
    ")\n",
    "\n",
    "\n",
    "Data_type = namedtuple('Data', ['xx', 'oo', 'yy'])\n",
    "\n",
    "# data loading for the IOB task\n",
    "def iterate_data(filename='train', *, max_examples=None):\n",
    "    file = open(f'iob/{filename}.tsv')\n",
    "    for n, row in enumerate(csv.DictReader(file, delimiter='\\t')):\n",
    "        if max_examples and n >= max_examples:\n",
    "            break\n",
    "        yield Data_type(\n",
    "            xx=tuple(row['xx'].split()),\n",
    "            oo=None,  # we are not dealing with partial observations in this homework\n",
    "            yy=tuple(row['yy'].split()) if 'yy' in row else None,\n",
    "        )\n",
    "\n",
    "        \n",
    "# data loading for the parsing task\n",
    "Parse_Data_type = namedtuple('ParseData', ['xx', 'aa'])\n",
    "def iterate_trees(filename='train', *, max_examples=None):\n",
    "    file = open(f'trees/{filename}.tsv')\n",
    "    for n, row in enumerate(csv.DictReader(file, delimiter='\\t')):\n",
    "        if max_examples and n >= max_examples:\n",
    "            break\n",
    "        yield Parse_Data_type(\n",
    "            xx=tuple(row['xx'].split(' ')),\n",
    "            aa=tuple(map(int, row['aa'].split())),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "09bd5b10-d78d-455d-a72e-709cdceeb405",
    "deletable": false
   },
   "source": [
    "Copy over your `IobTask0` from homework 2.  We will be reusing the IobTask as a a warm up to transition based neural parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d08c551d-0b55-4b0b-bd33-f91205b271da",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from seq2class_homework2 import (\n",
    "    IobTask0 as IobTask,\n",
    "    Integerizer,\n",
    "    F1\n",
    ")\n",
    "\n",
    "iob_task = IobTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ec8d53c9-cc80-4dc9-a085-de89ffb77d18",
    "deletable": false
   },
   "source": [
    "## PyTorch Basics\n",
    "\n",
    "For this assignment we will be using [PyTorch](http://pytorch.org/) to build a neural transition based parser.  We will build up to writing a full parser by building constructing a neural representation of our words from the character sequence of each word.  We will use our character representation to train a neural Iob tagger and eventually our neural parser.\n",
    "\n",
    "\n",
    "\n",
    "#### Documentation links:\n",
    "1. [Torch general documentation](http://pytorch.org/docs/stable/torch.html)\n",
    "2. [Torch neural network layers](http://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "#### Neural network layers that we will use through this assignment\n",
    "| Neural Layer | Use |\n",
    "|---|---|\n",
    "| [nn.Linear](http://pytorch.org/docs/master/nn.html#torch.nn.Linear) | A single feed forward linear layer with bias. |\n",
    "| [nn.LSTMCell](http://pytorch.org/docs/master/nn.html#torch.nn.LSTMCell) | Implements a single step of an LSTM returning the new hidden and cell states. |\n",
    "| [nn.Embedding](http://pytorch.org/docs/master/nn.html#torch.nn.Embedding) | Holds an embedding matrix for tokens indexed by an integer array. |\n",
    "| [nn.Parameter](http://pytorch.org/docs/master/nn.html#torch.nn.Parameter) | Holds a raw tensor but adds it to the list of parameters for training |\n",
    "\n",
    "#### Useful PyTorch functions :\n",
    "| Function | Use |\n",
    "|---|---|\n",
    "| [torch.cat](http://pytorch.org/docs/stable/torch.html#torch.cat) | concatenate tensors along a given dimension |\n",
    "| [torch.stack](http://pytorch.org/docs/stable/torch.html#torch.stack) | adds a new dimension when combing tensors |\n",
    "| [F.tanh](http://pytorch.org/docs/stable/nn.html#torch.nn.functional.tanh) | Hyperbolic tangent function (non-linearity) |\n",
    "| [F.softmax](http://pytorch.org/docs/stable/nn.html#torch.nn.functional.softmax) | Compute the softmax over a tensor |\n",
    "| [torch.zeros](http://pytorch.org/docs/stable/torch.html#torch.zeros) | Returns a new tensor filled with zeros |\n",
    "| [torch.rand](http://pytorch.org/docs/stable/torch.html#torch.rand) | Returns a new tensor filled with random values in the $[0, 1)$ interval |\n",
    "| [`Variable(..)`](http://pytorch.org/tutorials/beginner/former_torchies/autograd_tutorial.html#variable) | A variable tracks the operations applied to a tensor for use with back propagation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0ba5aa14-6ceb-43d2-9931-d4c0efed25a9",
    "deletable": false
   },
   "source": [
    "# Part 1: Backpropagating through Matrices and Checking your Answer\n",
    "\n",
    "Backward-mode automatic differentiation a.k.a. backpropagation is the algorithmic workhorse of \n",
    "deep learning. It fuses the [chain rule](https://en.wikipedia.org/wiki/Chain_rule), taken from calculus, and [memoization](https://en.wikipedia.org/wiki/Memoization), a technique from algorithms. \n",
    "\n",
    "Let\u2019s first talk about the calculus. As students, you likely spent a lot of time manually taking derivatives with respect to real scalars in univariate calculus and with respect to real vectors in multi-variate calculus. If you took complex analysis, you may have even taken derivatives with respect to complex-valued quantities. But what of matrices? In deep learning, we are often interested in the derivative with respect to a real matrix. For instance, consider this simple log-linear model for binary classification: $p(y \\mid x) = \\textit{sigmoid}(W x)$, where $x \\in \\mathbb{R}^d$ is the input to the model, $W \\in \\mathbf{R}^{2 \\times d}$ is a matrix of parameters. Typically, we choose $W$ so as to minimize the loss ${\\cal L}(W) = -\\sum_{i=1}^n \\log p(y^{(i)} \\mid x^{(i)})$, perhaps with a regularization terms, which we would achieve algorithmically by following the gradient $\\frac{\\partial L}{\\partial W}$. \n",
    "\n",
    "To get you comfortable with taking derivatives with respect to matrices, we often a series of pen-and-pencil exercises to get you warmed up. Note that the general strategy will be to break down the function into a series of sums, using the definition of the matrix operations, and then apply standard techniques from univariate calculus. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bc163f50-0695-4698-8518-190dd04e34c2",
    "deletable": false
   },
   "source": [
    "### Question 1: The Derivative of Latent Semantic Analysis (LSA)\n",
    "\n",
    "Suppose you have a large matrix $X \\in \\mathbb{R}^{N \\times M}$ and you would like to approximately factorize it.  We saw this *matrix factorization* problem in class: *latent semantic analysis (LSA)* is the case where $X_{ij}$ is the number of times word $i$ appears in context $j$.  In this question, however, we will generalize by allowing the entries of $X$ to be real numbers rather than counts.\n",
    "\n",
    "Let us try to express $X \\approx AB$ where $A \\in \\mathbb{R}^{N \\times K}$ and $B \\in \\mathbb{R}^{K \\times M}$.  Note that $\\textit{rank}(AB) \\leq K$.  By setting $K$ to a small value, we can ensure that this rank is less than the original $\\textit{rank}(X)$, which may be as large as $\\min(N,M)$.  Thus, we regard $AB$ as a low-rank approximation to $X$.\n",
    "\n",
    "Specifically, let's try to minimize ${\\cal L}_\\textit{lsa}(A, B) = \\frac{1}{2}||X - AB||^2_F$, where $||\\cdot||_F$ denotes the [Frobenius norm](http://mathworld.wolfram.com/FrobeniusNorm.html) of a matrix.\n",
    "\n",
    "While we can globally minimize this particular objective by running Singular Value Decomposition, one may also use gradient descent, albeit without the globally optimal guarantee. So, let's figure out the gradient of the objective with respect to the parameters\u2014namely the elements of $A$ and $B$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "2bf433f7-ed77-4b2b-93b2-88e1a1945d8a",
    "deletable": false
   },
   "source": [
    "#### The Gradient of Matrix Multiplication\n",
    "\n",
    "The goal is to compute $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial A}$ and $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial B}$.  But what does that even mean when $A$ and $B$ are matrices?  We'd better try temporarily eliminating the matrix notation and just using good old single-variable calculus:\n",
    "$$ {\\cal L}_\\textit{lsa}(A, B) = \\frac{1}{2}||X - AB||^2_F = \\frac{1}{2}\\sum_{i'=1}^N \\sum_{j'=1}^M (X_{i'j'} - \\sum_{k'=1}^K A_{i'k'} B_{k'j'})^2$$\n",
    "\n",
    "Now for any fixed $i,j,k$, you should be able to write down formulas for both $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial A_{ik}}$ and $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial A_{kj}}$.  (We used $i',j',k'$ in the objective function above so that you could keep the summation indices separate from the indices of the specific fixed variable that you are differentiating with respect to.)\n",
    "\n",
    "Congratulations: you have just written formulas for computing $NK + KM$ different partial derivatives.  It's convenient to store all those real numbers in a pair of matrices, which are what we call $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial A} \\in \\mathbb{R}^{N \\times K}$ and $\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial B} \\in \\mathbb{R}^{K \\times M}$.  \n",
    "\n",
    "Can you write formulas that compute those matrices using only matrix operations (which are fast in numpy and PyTorch)?  Check: the correct answer requires multiplication and subtraction on matrices.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial A} &= \\color{red}{\\text{FILL IN}} \\\\\n",
    "\\frac{\\partial {\\cal L}_\\textit{lsa}}{\\partial B} &= \\color{red}{\\text{FILL IN}} \\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2cd95e7f-bbf5-4495-b9f6-d16acc71349d",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "n = 5; k = 2\n",
    "# random initialization of the parameters\n",
    "A = Variable(torch.randn(n, k), requires_grad=True)\n",
    "B = Variable(torch.randn(n, k), requires_grad=True)\n",
    "# random positive matrix to factorize\n",
    "X = Variable(torch.exp(torch.randn(n, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "93811aca-c22c-4ee3-b367-a056701953cb",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def Llsa(A, B):\n",
    "    \"\"\"\n",
    "    Loss function for matrix factorization\n",
    "    \"\"\"\n",
    "    C = torch.mm(A, B.transpose(1, 0))\n",
    "    loss = 0.5 * ((X-C)**2).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "f4da44cd-8ed4-4ef5-a987-2a92955a9054",
    "deletable": false
   },
   "source": [
    "### Automatic Differentiation\n",
    "Recall that pyTorch will automatically compute gradients for you using [reverse-mode automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation). This algorithm was discussed and demoed in class. See it in action below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "73c2bc41-ac7c-4b90-abce-95c8772ed8c3",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "A.grad = None\n",
    "B.grad = None\n",
    "loss = Llsa(A, B)\n",
    "loss.backward()\n",
    "dLlsa_dA_auto = A.grad.data.numpy()\n",
    "dLlsa_dB_auto = B.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "e83b700a-fdef-4f7e-93cc-a995521212be",
    "deletable": false
   },
   "source": [
    "### Now, fill in the following functions with your answer from above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "70912acb-fa81-4165-8680-9a5e206dea68",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def dLlsa_dA(A, B):\n",
    "    \"\"\" Computes the derivative of L with respect to the matrix A\"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "f3e69886-1c60-45b8-a888-24c14a621ac8",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def dLlsa_dB(A, B):\n",
    "    \"\"\" Computes thederivative of L with respect to the matrix B \"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "af9b04a2-cd40-42f8-88fe-27bb6f51d533",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# the following two assert statements should pass if you did it right :-)\n",
    "assert np.allclose(dLlsa_dA_auto, (dLlsa_dA(A, B)), atol=1e-2)\n",
    "assert np.allclose(dLlsa_dB_auto, (dLlsa_dB(A, B)), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "0b0c5d95-f756-460f-b703-81f88d5e192e",
    "deletable": false
   },
   "source": [
    "## Question 3: The Derivative of Skip-Gram\n",
    "\n",
    "Again, let $X \\in \\mathbb{R}^{n \\times n}$ and let $A, B \\in \\mathbb{R}^{n \\times m}$. We will\n",
    "consider the function ${\\cal L}_{\\textit{skipgram}}(A, B) = \\sum_{i=1}^n \\sum_{j=1}^n X_{ij} \\log p(i \\mid j ; A, B)$, \n",
    "whose derivative you will find with respect to both $A$ and $B$. We define \n",
    "\n",
    "$p(i \\mid j; A, B) = \\textit{softmax}((AB^{\\top})_{:j})_i = \\frac{\\exp\\,(AB^{\\top})_{ij}}{\\sum_{i'=1}^n \\exp\\, (AB^{\\top})_{i'j}}$\n",
    "\n",
    "Recall from class that this objective is called the [skip-gram](https://en.wikipedia.org/wiki/Word2vec) objective, which is part of the word2vec toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "be8620c1-96f8-4ac6-be05-709a506b6e7c",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def Lskipgram(A, B):\n",
    "    logit = torch.mm(A, B.transpose(1, 0))\n",
    "    return (X * F.log_softmax(logit, dim=0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "970d24c7-1bc1-4667-bf65-256d458d8f99",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# HINT: these two matrices (and their names) should help you see relation\n",
    "# between the gradient of skip-gram's matrices and those of the log-linear model\n",
    "# you saw in NLP assignment 3. \n",
    "logit = torch.mm(A, B.transpose(1, 0))\n",
    "P = F.softmax(logit, dim=0)\n",
    "X_expected = torch.mm(P, torch.diag(X.sum(0).squeeze(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "27906fbb-b161-4795-ae44-e8a556d4830a",
    "deletable": false
   },
   "source": [
    "### Now, fill in the following functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "be3cdb30-8a05-4ea1-87df-40b83f974971",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def dLskipgram_dA(A, B):\n",
    "    \"\"\" Computes the derivative of L with respect to the matrix A\"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "dffa13f5-8509-4fb4-806b-f3da93ca6773",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def dLskipgram_dB(A, B):\n",
    "    \"\"\" Computes thederivative of L with respect to the matrix B \"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "7eb353ea-b7f9-45c5-8936-4762fa55932e",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# automatic differentiation again\n",
    "A.grad = None\n",
    "B.grad = None\n",
    "loss = Lskipgram(A, B)\n",
    "loss.backward()\n",
    "dLskipgram_dA_auto = A.grad.data.numpy()\n",
    "dLskipgram_dB_auto = B.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "162cc655-bd5f-448b-a196-d8da14c67c78",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# the following two assert statements should pass if you did it right :-)\n",
    "assert np.allclose(dLskipgram_dA_auto, (dLskipgram_dA(A, B)), atol=1e-2)\n",
    "assert np.allclose(dLskipgram_dB_auto, (dLskipgram_dB(A, B)), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "8e810ffb-934f-4e17-8511-9e3164d08978",
    "deletable": false
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Let\u2019s suppose, for a second, we didn\u2019t have an automatic differentiation toolkit available? Is there, perhaps, another way that we can use a computer to compute the gradient? The most common numerical method as our disposal is called the finite-difference check. In this exercise, I will derive the method for you and have you all implement.\n",
    "\n",
    "#### Background\n",
    "Consider a smooth function $f : \\mathbb{R}\\rightarrow \\mathbb{R}$. Recall from calculus,\n",
    "that for $x, \\varepsilon \\in \\mathbb{R}$, the first-order Taylor approximation of $f$ may be written\n",
    "as\n",
    "\n",
    "$\n",
    "f(x + \\varepsilon) = f(x) + \\varepsilon f'(x) + o(|\\varepsilon|^2)\n",
    "$\n",
    "\n",
    "Note that if little-o notation is unfamiliar to you, just interpret $o(|\\varepsilon|^2)$\n",
    "as the order of magnitude of the error term. More often, this formula is written as,\n",
    "\n",
    "$\n",
    "    f'(x) \\approx  \\frac{f(x + \\varepsilon) - f(x)}{\\varepsilon}\n",
    "$\n",
    "\n",
    "The equation above is termed the **forward difference** in the numerical analysis literature.  \n",
    "Note that in the limit as $\\varepsilon \\rightarrow 0$, the equation is exact. Indeed,\n",
    "you may recognize this as the definition of the derivative. We may also consider the\n",
    "**backward difference**\n",
    "\n",
    "$\n",
    "    f'(x) \\approx  \\frac{f(x) - f(x - \\varepsilon)}{\\varepsilon}\n",
    "$\n",
    "\n",
    "which follows were we to replace $(x+\\varepsilon)$ with $(x-\\varepsilon)$ in the derivation\n",
    "of the forward difference from the Taylor approximation. Averaging the forward and backward difference,\n",
    "yields the **central difference**.\n",
    "\n",
    "$\n",
    "f'(x) \\approx \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2\\varepsilon}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bdbb8c02-b076-40e4-9250-de33712a64ed",
    "deletable": false
   },
   "source": [
    "### Question 3: Operationalizing the finite-difference check\n",
    "\n",
    "Now, I am going to ask you to operationalize the finite-difference check. Given a function $f(x) = \\sin(x^2) + 10$, we are going to ask you to implement the finite-difference method and compare the output to a derivative you compute symbolically. Note that *checking* the correctness of derivative and gradient computations is a primary use case of the finite-difference method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "701b0b5b-572d-4acc-8870-9666702590a1",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\" a fun function\"\"\"\n",
    "    return np.sin(x**2) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "6e6128ea-deae-42ab-9183-30196045fb70",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def df(x):\n",
    "    \"\"\" compute the derivative of f symbolically\"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "70a868c9-5536-4ec6-afef-fa039f57c0a6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def df_fd(x, eps=1e-5):\n",
    "    \"\"\" compute the derivative of f using the finite-difference check\"\"\"\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "24c765df-05e7-4559-a36e-de017297a907",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# if you have done it right, these two checks should pass\n",
    "assert np.allclose(df(5.0), df_fd(5.0), atol=1e-2)\n",
    "assert np.allclose(df(-2.0), df_fd(-2.0), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "89c653a3-0d08-4720-9efd-ad4b25edc249",
    "deletable": false
   },
   "source": [
    "### Question 4: Extension to functions of many variables\n",
    "\n",
    "In the land of machine learning, we are generally interested in computing the derivative of a function\n",
    "of many variables: $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$. How do we extend the finite-difference check to this case? As it turns out, it's quite trivial. Say we have $f(x_1, \\ldots, x_n)$, to compute $\\nabla_{\\mathbf{x}} f$, we simply perform the univariate finite-difference check on each component of the input. This next question, we ask that you write a function to do this for a parameter $Y \\in \\mathbb{R}^{n \\times m}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d6bc97c5-43e8-4b87-adb8-5aebabc60d32",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def finite_difference(Y, f, eps=1e-2):\n",
    "    \"\"\" compute the finite-difference approximation for the function f\"\"\"\n",
    "    # populate this numpy matrix\n",
    "    dY = np.zeros((n, k))\n",
    "    ### STUDENTS START\n",
    "    raise NotImplementedError()  # REPLACE ME\n",
    "    ### STUDENTS END\n",
    "    return dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "acb278df-e849-45fa-8523-212ecf699e7e",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# the following two assert statements should pass if you did it right :-)\n",
    "assert np.allclose(dLskipgram_dA_auto, finite_difference(A, lambda Y: Lskipgram(Y, B)), atol=1e-2)\n",
    "assert np.allclose(dLskipgram_dB_auto, finite_difference(B, lambda Y: Lskipgram(A, Y)), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "bcba3d99-15f4-46c7-bc1a-986062ab3905",
    "deletable": false
   },
   "source": [
    "### Question 5: Runtime Analysis of the the finite-difference check\n",
    "\n",
    "Let $f : \\mathbb{R}^{n \\times k} \\rightarrow \\mathbb{R}$ be a smooth function, e.g., the objective of LSA or skip-gram. Give a big-O analysis of the runtime for the finite-difference method in terms of $n$ and $k$, assuming you can compute the value of the function in $O(1)$. Now, give a big-O analysis of the runtime of automatic differentiation in terms of $n$ and $k$? What does this analysis ever tell you about the practicality of the finite-difference method for computing the derivatives within an optimization routine for neural networks?\n",
    "\n",
    "$\\color{red}{\\text{FILL IN}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d2261a0d-687f-46e1-8b1d-d545c4cb9988",
    "deletable": false
   },
   "source": [
    "# Part 2: Embedding words using their character representation\n",
    "\n",
    "As a warm-up, we will embed actual words using recurrent neural networks, specifically using long short-term memory (LSTM). We would like for each word to be represented as a single fixed sized vector, this will allow us to more easily feed into later stages of our training pipe line.  We are going to accomplish this using a character level LSTM over the characters in the word.\n",
    "\n",
    "For each word in the sequence `xx`, we are going to split it into characters and represent each character an integer.  To pass this representation into the LSTM, we will use a one-hot encoding, meaning at each step we will apply the LSTM to a tensor that contains a single 1 value and zeros otherwise.\n",
    "\n",
    "Throughout this homework, we will be using [LSTMCell](http://pytorch.org/docs/master/nn.html#torch.nn.LSTMCell), which only applies the a single step of the LSTM.  This means that you will have to handle passing the hidden states between different time steps of the LSTM\n",
    "\n",
    "### Question 6\n",
    "Your next task is to analyze the code toy model below. Pay close attention to the `def foward` method, which loops over the characters\n",
    "in the input word, encodes each as a [one-hot vector](https://en.wikipedia.org/wiki/One-hot), and, then,\n",
    "calls ``self.character_lstm``. In short, you are unfolding the LSTM over the character stream. The sanity checks below should help guide you. You will implement similar methods in the next questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "60fe60cb-9e3c-4e5d-a0f3-38508b781fda",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class CharacterLSTMPreprocessModule(nn.Module):\n",
    "    \"\"\"\n",
    "    CharacterLSTMPreprocessModule takes an `xx` input string, and maps it to an embedding tensor using a\n",
    "    character level LSTM over each input word.  We \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, integerizer):\n",
    "        super().__init__()\n",
    "        \n",
    "        # string integerizer from homework 2\n",
    "        self.integerizer = integerizer\n",
    "        \n",
    "        # the parameters and submodules for this module\n",
    "        self.character_lstm = nn.LSTMCell(len(integerizer), HIDDEN_SIZE)\n",
    "        self.character_lstm_init = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "        \n",
    "    def forward(self, *, xx):\n",
    "        \"\"\"\n",
    "        Preprocess the input sequence xx into something that we can then process\n",
    "        at the token level.\n",
    "        \"\"\"\n",
    "        output = []\n",
    "        for x in xx:\n",
    "            # initalize the hidden state of the LSTM\n",
    "            cx = self.character_lstm_init\n",
    "            hx = torch.tanh(cx)\n",
    "            for c in x:\n",
    "                i = torch.zeros(len(self.integerizer))\n",
    "                i[self.integerizer.index(c)] = 1\n",
    "                hx, cx = self.character_lstm(Variable(i), (hx, cx))\n",
    "            output.append(hx)\n",
    "        return torch.stack(output, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "6fe62c65-ff79-439c-8d39-c2920ea7c710",
    "deletable": false
   },
   "source": [
    "#### Basics sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "a29974f2-8138-494e-aa17-2e41efe035f6",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# basic tests for the character LSTM module\n",
    "\n",
    "dutch_character_integerizer = Integerizer(tuple(set(w for d in iterate_data('train') for w in ' '.join(d.xx))))\n",
    "\n",
    "dutch_preprocess = CharacterLSTMPreprocessModule(dutch_character_integerizer)\n",
    "\n",
    "print('Parameters in model:\\n\\t'+ '\\n\\t'.join(list(name for name,value in dutch_preprocess.named_parameters())))\n",
    "\n",
    "# get a first example out of the dutch training data\n",
    "xx, oo, yy = next(iterate_data('train-small'))\n",
    "xx_processed = dutch_preprocess(xx=xx)\n",
    "\n",
    "# check that the output is a PyTorch variable and that the size has\n",
    "# a 1 in the first dimention to represent the mini-batch\n",
    "# the length of the input sentence for the second dimention\n",
    "# the HIDDEN_SIZE to represent the size of the hidden state that we are using to represent words\n",
    "assert isinstance(xx_processed, Variable)\n",
    "assert xx_processed.shape == (1,len(xx),HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "d11702a5-892a-4b88-80fa-ef5aec6919f6",
    "deletable": false
   },
   "source": [
    "#### Basic training task for `CharacterLSTMPreprocessModule`\n",
    "\n",
    "The above only checked that the output of `CharacterLSTMPreprocessModule` was the correct shape, however to check that the model is actually capable of learning a function, we need to set up a simple task.\n",
    "\n",
    "Below, we have defined `SimpleWordClassification` which takes the embedding of a word and attempts to predict if the word contains the letter 'e'.\n",
    "This model classifies a word by performing $p_i = \\sigma(W e(\\text{word}_i) + b)$, where it applies a linear transform of $Wx + b$ to the output of our embedding layer $e(\\cdot)$ and then a sigmoid function to map to $[0, 1]$.\n",
    "\n",
    "To train this model, we need to define a *training loss*.  For this simple model we define the training loss as the squared difference between the correct label and the predicted label $\\sum_i (l_i - p_i)^2$.  To train the model, we need to take the derivative of *all* the parameters with respect to the scalar that represents the training loss.  This is done for us *automatically* when calling PyTorch's `.backward()` method on the loss variable.\n",
    "\n",
    "For this simple model, we are choosing to train it using just standard [SGD](http://pytorch.org/docs/master/optim.html#torch.optim.SGD) like in the previous homeworks. However, this function is again provided for by PyTorch.  Using `torch.optim.SGD`, we take a list of all the parameters in the model (which we can get as `model.parameters()`) and a learning rate.  Once we have computed the gradients (as described above), `optimizer.step()` to take a single step in the direction of the gradient.  Note, that the optimizers in PyTorch are always seeking to *minimize* the loss (so if you want to maximize a value do `(-reward).backward()`).\n",
    "\n",
    "If you have correctly implemented `CharacterLSTMPreprocessModule` you should see that large difference between the positive and negative training examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "df418e5f-b7d6-4630-9ead-55bd930c21a7",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class SimpleWordClassification(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.word_embedding = dutch_preprocess\n",
    "        self.word_classifier = nn.Linear(HIDDEN_SIZE, 1)\n",
    "        \n",
    "    def forward(self, xx):\n",
    "        embedding = self.word_embedding(xx=xx)  # this will call self.word_embedding.forward(....)\n",
    "        return F.sigmoid(self.word_classifier(embedding))\n",
    "    \n",
    "dutch_words = set(x for d in iterate_data('train') for x in d.xx)\n",
    "# split the words such that there is some classification boundary that we can learn\n",
    "# here we are using words that contain the letter 'e'\n",
    "positive_words = set(word for word in dutch_words if 'e' in word)\n",
    "negative_words = dutch_words - positive_words\n",
    "\n",
    "simple_classifier = SimpleWordClassification()\n",
    "\n",
    "optimizer = torch.optim.SGD(simple_classifier.parameters(), lr=.05)\n",
    "for _ in range(2):\n",
    "    for word in dutch_words:\n",
    "        score = simple_classifier([word])\n",
    "        loss = (int(word in positive_words) - score)**2\n",
    "\n",
    "        # compute the gradient of all parameters with respect to the loss variable\n",
    "        loss.backward()\n",
    "\n",
    "        # make the optimization method take a single step\n",
    "        optimizer.step()\n",
    "\n",
    "        # the gradient is accumulated into special a .grad value each parameter.\n",
    "        # we need to zero .grad otherwise PyTorch will just accumulate the next \n",
    "        # gradient on top of the old one\n",
    "        #\n",
    "        # Keeping .step() seperate from .zero_grad() is useful in the case that \n",
    "        # there are multiple operations which will use the same gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    # quickly test how well the model is doing on the *training* data\n",
    "    positive_average = simple_classifier(list(positive_words)).mean()\n",
    "    negative_average = simple_classifier(list(negative_words)).mean()\n",
    "    \n",
    "    print(f'Positive example average: {float(positive_average)}, '\n",
    "          f'Negative example average: {float(negative_average)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7a74bd5b-6f5a-4d53-bb5f-c78c5a173e5f",
    "deletable": false
   },
   "source": [
    "## Part 3: Transition-based Tagging\n",
    "Throughout the remainder of this homework, we will be defining transition models which define *how* we transition from an \"opaque\" state $\\mathbf s$ to another \"opaque\" state $\\mathbf s'$ given an action $y_i$.  During each transition, we will compute a score $g = G(\\mathbf s')$ which we will learn such that we generate the correct $\\mathbf y$ output string.\n",
    "\n",
    "$$ f: (\\mathbf s, y_i) \\mapsto (\\mathbf s', g) $$\n",
    "\n",
    "Below, you can see the base class for our transition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "bafd0b2e-68b8-465b-a120-1210bd6748eb",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class TransitionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A base class for all of our transistion models that we are going to implement in this homework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task):\n",
    "        super().__init__()\n",
    "        self.task = task\n",
    "\n",
    "    def iterate_y(self, *, state, xx, yy_prefix):\n",
    "        \"\"\"\n",
    "        Iterate over transition actions y that we can take given the current state, yy_prefix and xx\n",
    "        \"\"\"\n",
    "        yield from self.task.iterate_y(xx=xx, yy_prefix=yy_prefix)\n",
    "        \n",
    "    def initial_state(self, *, xx, xx_embedding):\n",
    "        \"\"\"\n",
    "        Return the initial state representation given the input xx.\n",
    "    \n",
    "        This could include running a backwards LSTM over the input sequence\n",
    "        as well as creating an empty forward LSTM state.\n",
    "        \"\"\"    \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, *, state, xx, xx_embedding, yy_prefix, y):\n",
    "        \"\"\"\n",
    "        Perform the forward $f$ function transition.  This should map s -> s' and \n",
    "        Score the state s' using the learned G function.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "83a78f91-51d4-493d-bb6c-1c555c05cffc",
    "deletable": false
   },
   "source": [
    "## IOB Transition Model\n",
    "\n",
    "For our IOB transition-based tagger, we will have a backwards LSTM which is encoding the words we have *yet* to see in the sentence as well as a forward LSTM which encodes which word we just read and the IOB tag that we chose to assign to that word.\n",
    "\n",
    "<img width=450px src='images/iob-lstm.png'>\n",
    "\n",
    "In the above figure, we just processed the third word $x_3$ and assigned it tag $y_3$.  Each circle represents a step of the LSTM where we are passing the hidden state to the next time step.  As we consume more tokens of the $\\mathbf x$ input, we will *pop* off states of the backwards LSTM which represents the lookahead, and we will *push* the new representation computed by the forward LSTM.\n",
    "\n",
    "You should probably look at the [decision agent](#DecisionAgent) below to see exactly how we are going to use the transition model before you attempt to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "dd15fe76-ee14-4efb-baa6-551d62e0cca5",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class IobTransitionModel(TransitionModel):\n",
    "    \"\"\"\n",
    "    This module represents the operations that are looking forward at each step\n",
    "    \n",
    "    Note, that there is a lot of copying of arrays which should maybe help with keeping the different components\n",
    "    isolated, but I would probably not do that in practice as I think that this is a bit awkard?\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iob_task):\n",
    "        super().__init__(iob_task)\n",
    "        \n",
    "        # the lstms that encode the input sequence.\n",
    "        # the input for the forward state should be our representation for each word and\n",
    "        # a one hot encoding for which IOB tag we are generating\n",
    "        self.forward_lstm = nn.LSTMCell(HIDDEN_SIZE + 3, HIDDEN_SIZE)\n",
    "        self.backward_lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        \n",
    "        # score the current state given the hidden forward and backward LSTMs state.\n",
    "        self.score_function = nn.Linear(HIDDEN_SIZE*2, 1)\n",
    "        \n",
    "        # The initial hidden states, represents the EOS and BOS for the respective LSTMs\n",
    "        self.lstm_init_backwards = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "        self.lstm_init_forwards = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "        \n",
    "    def iterate_y(self, *, state, xx, yy_prefix):\n",
    "        \"\"\"\n",
    "        Iterate through valid IOB assignments given the prefix.\n",
    "        If we are at the end of the string, then do not yield any additional y actions \n",
    "        to indicate that we are done.\n",
    "        \"\"\"\n",
    "        if len(yy_prefix) < len(xx):\n",
    "            yield from self.task.iterate_y(xx=xx, yy_prefix=yy_prefix)\n",
    "        \n",
    "    def initial_state(self, *, xx, xx_embedding):\n",
    "        \"\"\"\n",
    "        Return the initial state vector for this model\n",
    "        xx is a vector represention of this input that comes from the preprocessing step\n",
    "        The preprocessing step might select the word vectors or use a character LSTM to embed the words\n",
    "        \"\"\"\n",
    "        lookahead = []\n",
    "        cx = self.lstm_init_backwards\n",
    "        hx = torch.tanh(cx)  # I suppose that this is suppose to be times the o output symbol? which we don't have\n",
    "        lookahead = [hx]\n",
    "        \n",
    "        for i in range(xx_embedding.shape[1]-1, -1,-1):  # run this backwards through the states\n",
    "            x = xx_embedding[:,i]\n",
    "            hx, cx = self.backward_lstm(x, (hx, cx))\n",
    "            lookahead.append(hx)\n",
    "        cx = self.lstm_init_forwards\n",
    "        hx = torch.tanh(cx)\n",
    "        # return the lookahead for the x_{0:n} and an empty initial forward state (hx, cx)\n",
    "        return tuple(lookahead), (hx, cx)\n",
    "    \n",
    "    def forward(self, *, state, xx, xx_embedding, yy_prefix, y):\n",
    "        \"\"\"\n",
    "        Take the previous state which is an opaque blob that represents the neuralized path representing\n",
    "        this state\n",
    "        as well as the x label that we are currently reading and \n",
    "        \"\"\"\n",
    "        lookahead, (hx, cx) = state\n",
    "        \n",
    "        x = xx_embedding[:, len(yy_prefix)]  # get the representation for this timestep\n",
    "        yi = Variable(torch.zeros(1, 3))\n",
    "        yi[0, 'IOB'.index(y)] = 1\n",
    "        \n",
    "        # this is a generative model, so we are jointly scoring P(x,y) which means we concatenate\n",
    "        # the embedding representation to a one hot embedding of IOB\n",
    "        inp = torch.cat((x, yi), 1)\n",
    "        \n",
    "        # compute the hidden states of the LSTM (hx, cx) and the score function\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "            \n",
    "        # return the tuple for the next state which is the lookahead with the list slicing off one state\n",
    "        # and the most recent hidden states from the forward passes with the LSTM\n",
    "        lookahead = lookahead[:-1]\n",
    "       \n",
    "        return score, (lookahead, (hx, cx))\n",
    "\n",
    "IobTransitionModel(IobTask())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "a3a18628-55f7-466a-b81d-0c4f5a77c95f",
    "deletable": false
   },
   "source": [
    "### Training a Transition Model\n",
    "\n",
    "To train our transition model, we would ideally like to maximize the log probability of $P(\\mathbf y \\mid \\mathbf x)$, however, we are unable to efficiently compute the normalizing function $Z(\\mathbf x)$ as we do not have a dynamic program over the $\\mathbf y$ strings and thus would require computing the exponentially sized $\\mathcal{Y}$ set.\n",
    "\n",
    "Instead, we are going to train our transition model to assign a high score to the correct path when using a decision agent.\n",
    "\n",
    "Below, you will find `BrokenGreedyDecisionAgent`.  This agent correctly implements the *interface* for working with a `TransitionModel`, however when trying to use it for training you will observe some strange behavior that we will correct later in this assignment.\n",
    "\n",
    "<a name=\"DecisionAgent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fa47aca5-9b9c-4523-81aa-2fd180979c1f",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class PyTorchDecisionAgent(nn.Module, DecisionAgent):\n",
    "    \"\"\"\n",
    "    Base class for our Decision Agent class using the PyTorch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task, preprocessor, model):\n",
    "        # init the base pytorch module\n",
    "        nn.Module.__init__(self) \n",
    "        \n",
    "        self.task = task\n",
    "        self.preprocessor = preprocessor\n",
    "        self.model = model\n",
    "        \n",
    "    def decision(self, *, xx, oo=None):\n",
    "        \"\"\"\n",
    "        Call the self.forward() method which implements the decision rule\n",
    "        \"\"\"\n",
    "        assert oo is None, \"Our Neural models do not support oo values\"\n",
    "        loss, yy = self(xx=xx)  # through pytorch this calls self.forward()\n",
    "        return yy\n",
    "\n",
    "    def forward(self, *, xx, yy=None):\n",
    "        \"\"\"\n",
    "        Implement the decision agent's decoding rule.\n",
    "        \n",
    "        Arguments:\n",
    "            `xx`: The input string\n",
    "            `yy`: The our desired output.  If unset, run the decoding rule and select the \"best\" yy\n",
    "        \n",
    "        Returns a tuple of (loss of the selected yy, and the selected yy)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ce897083-b96e-4345-b385-d17c050481bf",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BrokenGreedyDecisionAgent(PyTorchDecisionAgent):\n",
    "    \"\"\"\n",
    "    This Decision Agent performs a greedy decoding of output sequence.\n",
    "    It is complete and ment to serve as an example for how you can structure other decision agents in this\n",
    "    homework, however it is *broken* as we will see later in this assignment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, *, xx, yy=None):\n",
    "        \"\"\"\n",
    "        xx represents input sequence\n",
    "        yy represents the gold sequence if known\n",
    "        \"\"\"\n",
    "        \n",
    "        # run the preprocessor to generate a representation for each token in the input xx\n",
    "        xx_embedding = self.preprocessor(xx=xx)\n",
    "        \n",
    "        # create the initial state for our decoding model\n",
    "        state = self.model.initial_state(xx=xx, xx_embedding=xx_embedding)\n",
    "        \n",
    "        yy_prefix = []\n",
    "        loss = 0  # this is the loss that we are collecting at each step\n",
    "        while True:\n",
    "            actions = []\n",
    "            action_scores = []\n",
    "            action_states = []\n",
    "            \n",
    "            for y in self.model.iterate_y(xx=xx, yy_prefix=yy_prefix, state=state):\n",
    "                # call the forward method on the model\n",
    "                # The model should return a score and a new state\n",
    "                nscore, nstate = self.model(xx=xx, \n",
    "                                            xx_embedding=xx_embedding,\n",
    "                                            state=state, \n",
    "                                            yy_prefix=yy_prefix, \n",
    "                                            y=y)\n",
    "                actions.append(y)\n",
    "                action_scores.append(nscore)\n",
    "                action_states.append(nstate)\n",
    "                \n",
    "            if len(actions) == 0:\n",
    "                # there were no new actions to perform, so we must have reached the end\n",
    "                break\n",
    "            \n",
    "            if yy is not None:\n",
    "                # then there is a gold yy sequence, so we are going to choose the action that matches the gold path\n",
    "                action = actions.index(yy[len(yy_prefix)])\n",
    "            else:\n",
    "                # there is no gold action, so choose the one that is the \"best\"\n",
    "                action = max(range(len(actions)), key=lambda i: float(action_scores[i]))\n",
    "            \n",
    "            # we are trying to minimize the loss, so we add the negative action score\n",
    "            # as we want to maximize the action score of along this path\n",
    "            loss += -action_scores[action]\n",
    "            # the state now holds whatever state was generated by our underlying model of the selected action\n",
    "            state = action_states[action]\n",
    "            # add the selected action the the prefix of the yy string that we are generating\n",
    "            yy_prefix.append(actions[action])\n",
    "        # we are done decoding this sequence\n",
    "        # return the loss that we calculated along the way as well as the yy prefix as it contains all of yy\n",
    "        return loss, tuple(yy_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ca10b9b7-198f-4464-a9d0-7c6d958b6f20",
    "deletable": false
   },
   "source": [
    "The `BrokenGreedyDecisionAgent` correctly implements the *interface* for working with our models, so you can use this to tests that you have correctly implemented `CharacterLSTMPreprocessModule` and `IobModule`, however when training you should observe some strange behavior.\n",
    "\n",
    "What do you observe about the loss.  How does this model perform on the testing data?  Why do you think that is?\n",
    "\n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n",
    "Fill in `LocallyNormalizedGreedyDecisionAgent` to change the way that we are computing loss to the product of the locally normalized actions at each step.  **Mention that this should be using the softmax over the scores of the states**\n",
    "\n",
    "\n",
    "Some discussion about the `PyTorchTrainer` and using [Adam](http://pytorch.org/docs/master/optim.html#torch.optim.Adam) as our accelerated decent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "0a3ddfc4-ce10-4046-bbf4-6168b31ca009",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import time\n",
    "class PyTorchTrainer(object):\n",
    "    \n",
    "    def __init__(self, trainable_agent, epochs=1, evaluate=None, optimizer=None):\n",
    "        self._model = trainable_agent\n",
    "        if optimizer is None:\n",
    "            # create an optimizer with the default settings\n",
    "            # model.parameters() is a list of all the trainable parameters in the model\n",
    "            optimizer = torch.optim.Adam(self._model.parameters())\n",
    "        self._optimizer = optimizer\n",
    "        self._epochs = epochs\n",
    "        self._evaluate = evaluate\n",
    "        \n",
    "    def train(self, dataset):\n",
    "        iteration = 0\n",
    "        dataset = list(dataset)\n",
    "        running_loss = 0\n",
    "        start = time.time()\n",
    "        for _ in range(self._epochs):\n",
    "            shuffle(dataset)\n",
    "            for example in dataset:\n",
    "                # compute the loss from the model (trainable decision agent)\n",
    "                loss, *_ = self._model(xx=example.xx, yy=example.yy)\n",
    "                # compute the gradients on the computation graph\n",
    "                loss.backward()  \n",
    "                # make the optimizer take a step using the computed gradients\n",
    "                self._optimizer.step()\n",
    "                # zero out the gradients for the next step\n",
    "                self._optimizer.zero_grad()\n",
    "                running_loss = running_loss * .99 + float(loss)\n",
    "                iteration += 1\n",
    "                if iteration % 50 == 0:\n",
    "                    # print progress\n",
    "                    done = iteration / (len(dataset) * self._epochs)\n",
    "                    now = time.time()\n",
    "                    total_time = (now - start) / done\n",
    "                    sys.stdout.write(f'\\r\\ttrained for {iteration} iterations, loss {running_loss/100} '\n",
    "                                     f'{int(done*100)}% time: {int((now - start) / 60)}/{int(total_time / 60)} (min)  ') \n",
    "            if self._evaluate:\n",
    "                sys.stdout.write('\\n')\n",
    "                self._evaluate(self._model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "36a6caa4-60b4-451e-9d46-8a29590f4be4",
    "deletable": false
   },
   "source": [
    "Try out your `IobTransitionModel` to ensure that everything is working before moving on to the next part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "099e2b79-157a-4318-92aa-e88c7803cf56",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "iob_model = IobTransitionModel(iob_task)\n",
    "iob_preprocess = CharacterLSTMPreprocessModule(dutch_character_integerizer)\n",
    "greedy_iob = BrokenGreedyDecisionAgent(iob_task, iob_preprocess, iob_model)\n",
    "\n",
    "trainer = PyTorchTrainer(\n",
    "    greedy_iob, \n",
    "    epochs=1,\n",
    "    evaluate=lambda x: x.test_F1(iterate_data('dev'))\n",
    ")\n",
    "\n",
    "%time trainer.train(iterate_data('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "49687e74-65a2-4e0e-b978-068c065bc787",
    "deletable": false
   },
   "source": [
    "1. What loss did your `IobTransitionModel` get after training with the `BrokenGreedyDecisionAgent`:  \n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n",
    "2. What is the *lower bound* on the training loss when using `BrokenGreedyDecisionAgent`:  \n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n",
    "3. How well dose your model perform on the development data after using `BrokenGreedyDecisionAgent`, what possible explanations are there for this performance?  \n",
    "**Answer:** <span style='color:red'>FILL IN</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7a13a093-ffd7-42e1-8c51-f7973091c7f2",
    "deletable": false
   },
   "source": [
    "### Locally Normalized Greedy Decision Agent\n",
    "\n",
    "\n",
    "In the above decision agent we defined the training loss to be the sum of score assigned to each action ($-\\sum_i G_{y_i}(\\mathbf s_i)$).  Now we are going to try changing this to a locally normalized model or a [MEMM](https://en.wikipedia.org/wiki/Maximum-entropy_Markov_model).\n",
    "\n",
    "<img width=450px src='images/memm.png'>\n",
    "\n",
    "In a memm, we are going to define the training loss to be the negative log probability of all the decision that we have to make along the way.\n",
    "\n",
    "$$ \\text{training loss} = -\\log \\prod_i p(\\mathbf s_i) = - \\sum_i \\log p(\\mathbf s_i) $$\n",
    "\n",
    "Just like in our previous Boltzmann models, the probability will be defined as $p(\\mathbf s_i) = \\frac{\\exp G(s_i)}{\\sum_{y_i \\in \\mathcal{Y}} G(f(s_{i-1}, y))}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2799c01e-25b5-45c5-a775-70bf0e74bdce",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class LocallyNormalizedGreedyDecisionAgent(PyTorchDecisionAgent):\n",
    "    \n",
    "    def forward(self, *, xx, yy=None):\n",
    "        \"\"\"\n",
    "        xx represents input sequence\n",
    "        yy represents the gold sequence if known\n",
    "        \"\"\"    \n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        return loss, tuple(yy_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d08a207d-1be5-45f0-8585-f4cac0cbbfcb",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "iob_model = IobTransitionModel(iob_task)\n",
    "iob_preprocess = CharacterLSTMPreprocessModule(dutch_character_integerizer)\n",
    "greedy_iob = LocallyNormalizedGreedyDecisionAgent(iob_task, iob_preprocess, iob_model)\n",
    "\n",
    "trainer = PyTorchTrainer(\n",
    "    greedy_iob, \n",
    "    epochs=3,\n",
    "    evaluate=lambda x: x.test_F1(iterate_data('dev')))\n",
    "\n",
    "%time trainer.train(iterate_data('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "586e6fe0-b168-4f8e-8bef-1f0414bc5203",
    "deletable": false
   },
   "source": [
    "1. What is the lower bound of the loss for `LocallyNormalizedGreedyDecisionAgent`  \n",
    "**Answer**: <span style='color:red'>FILL IN</span>\n",
    "2. How well does `LocallyNormalizedGreedyDecisionAgent` perform on the Iob task, why do you think that this agent is better or worse than the previous broken agent.  \n",
    "**Answer**: <span style='color:red'>FILL IN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "09f4029c-e3d4-488c-a994-5ad14528c178",
    "deletable": false
   },
   "source": [
    "## Beam decoding\n",
    "\n",
    "In the greedy decoding agent above, we are only looking at the one best action.  Additionally, we are only looking at the actions that we can take given that we *made* to to the correct action so far, and as such we are only able to perform local normalization.\n",
    "\n",
    "Instead, we would like to work with a *globally* normalized model (like we have seen in the previous two assignments).  This requires that we are able to compute a $Z(\\mathbf x)$.  However, given that we are unable to efficiently compute the exact value of $Z(\\mathbf x)$, we are going to instead approximate $Z$.\n",
    "\n",
    "To estimate $Z$ during training and introduce a more powerful decision agent we are going to use [Beam search](https://en.wikibooks.org/wiki/Artificial_Intelligence/Search/Heuristic_search/Beam_search).  Instead of just maintaining the one best, we are going to have a list of the top $k$ possibilities.  We then approximate $Z(x) = \\sum_{j=0}^k \\exp(G(\\mathbf s_n^{(i)}))$, as the sum of sequences that made it to the end of the beam.\n",
    "\n",
    "Here is the basic algorithmic description of beam search:\n",
    "\n",
    "```text\n",
    "    beam = [ (0, initial_state) ]\n",
    "    while not done:\n",
    "        next_beam = []\n",
    "        for item on beam:\n",
    "            for next possible y actions for item:\n",
    "                g, next_state = f(item, y) \n",
    "                score = ???\n",
    "                next_beam.add((score, next_state))\n",
    "        beam = choose top k items from next_beam\n",
    "    loss = -log P(gold sequence) = -log exp(gold) / Z(x)\n",
    "```\n",
    "\n",
    "Hints: \n",
    "1. This is a globally normalized model, the score of a sequence is the *sum* of $g$ from all steps instead of the score of just the most recent operation.\n",
    "2. When you are training your model, it is possible that the *gold* sequence falls off of the beam and will not make it to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "ba4d575b-b86d-489c-88bf-80e605b3a414",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class BeamDecisionAgent(PyTorchDecisionAgent):\n",
    "        \n",
    "    def __init__(self, *args, beam_size=10, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.beam_size = beam_size\n",
    "    \n",
    "    def forward(self, *, xx, yy=None):\n",
    "        \"\"\"\n",
    "        Perform beam search\n",
    "        return the loss for the best path and the best path\n",
    "            xx is the input sequence\n",
    "            yy (if set) represents the gold sequence.  Return the loss for the yy sequence\n",
    "        \"\"\"\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        \n",
    "        if yy:\n",
    "            # if there is a gold yy sequence, then we should return that path\n",
    "            # loss should correspond to the path that we are returning\n",
    "            assert tuple(best_yy_path) == tuple(yy)\n",
    "        \n",
    "        return loss, best_yy_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "fa919a90-a354-455e-aec2-7acce43455ff",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "iob_model = IobTransitionModel(iob_task)\n",
    "preprocess = CharacterLSTMPreprocessModule(dutch_character_integerizer)\n",
    "beam_iob = BeamDecisionAgent(iob_task, preprocess, iob_model)\n",
    "\n",
    "trainer = PyTorchTrainer(beam_iob, \n",
    "                         epochs=3, \n",
    "                         evaluate=lambda x: x.test_F1(iterate_data('dev')))\n",
    "\n",
    "%time trainer.train(iterate_data('train'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b1b2ce66-1ee6-434d-95e2-5e4f779e4e09",
    "deletable": false
   },
   "source": [
    "# Part 4: Recurrent Neural Shift-Reduce Parsing\n",
    "\n",
    "For our next act, we will introduce a recurrent neural shift-reduce\n",
    "parser. In contrast to CKY and Earley's algorithm, which have a worst-case\n",
    "runtime of $O(n^3)$ for sentences of length $n$, shift-reduce parsers\n",
    "run in $O(n)$ time. This gives them a practical relevance in\n",
    "real-world applications benefit from syntactic information. Also, in\n",
    "contrast to 601.465, we will focus on dependency grammar, rather than\n",
    "constituency grammar.\n",
    "\n",
    "An excellent introduction to dependency parsing may be found in\n",
    "the [tome](https://www.amazon.com/Dependency-Synthesis-Lectures-Language-Technologies/dp/1598295969/ref=sr_1_1?ie=UTF8&qid=1524716345&sr=8-1&keywords=dependency+parsing), which may be downloaded for free on\n",
    "the Johns Hopkins network. For completeness, we will briefly overview\n",
    "the formalism. Consider the sentence:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Formally, let $\\mathbf{x}\n",
    "\\in \\Sigma^*$, where $\\Sigma$ is an alphabet, a finite non-empty set,\n",
    "where we have augmented $\\Sigma$ with a distinguished root symbol\n",
    "*ROOT*. Given a sentence of length $|\\mathbf{x}| = n$, a dependency parse of\n",
    "$\\mathbf{x}$, which we will denote ${\\cal T}(\\mathbf{x})$, is is a directed tree on\n",
    "$(n+1)$ nodes, rooted at ROOT. There is a bijection between the\n",
    "non-ROOT nodes of ${\\cal T}(\\mathbf{x})$ and the words of $\\mathbf{x}$. In this\n",
    "assignment, we will focus on *projective* dependency\n",
    "parsing. Visually, a dependency parse is considered projective if,\n",
    "drawing all the arcs above the sentence, it is the case that none of\n",
    "them cross. The sentence above has a projective parse.\n",
    "We refer the reader to [McDonald et al. (2005)](http://www.aclweb.org/anthology/H05-1066) for an example of an English sentence with a non-projective parse.\n",
    "For a formal definition of projectivity, see [Nivre (20080)](https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-056-R1-07-027). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ff3f30a0-d54f-4836-af14-129fb8633c87",
    "deletable": false
   },
   "source": [
    "### Question 9\n",
    "Before moving onto shift-reduce parsing, we will allow for a brief interlude to consider dependency parsing\n",
    "using an algorithm you already know.  There is a tight relationship between projective dependency parses and constituency parses. In this question, we ask that you design a dynamic-programming\n",
    "algorithm to parse dependency grammar. We expect you to do this the following way. Given an input sentence $\\xx$ of length $n$,\n",
    "design a sentence-specific context-free grammar ${\\cal G}(\\mathbf{x})$ that, when provided to CKY, will yield dependency parses of $\\mathbf{x}$. What is the runtime (in terms of\n",
    "$n$) of this algorithm?\n",
    "\n",
    "**Answer:** $\\color{red}{\\text{FILL IN}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "7dee9a62-0680-4f58-b33f-e147fc0c8b8a",
    "deletable": false
   },
   "source": [
    "### Question 10\n",
    "If you're on the right track, you will have found an answer that is $\\omega(n^3)$. Can we do better? Eisner's algorithm provides an elegant $O(n^3)$ solution.\n",
    "A sketch of the algorithm may be found here in [Eisner 1996](http://cs.jhu.edu/~jason/papers/eisner.acl96.pdf). We ask that you read the paper linked,\n",
    "decipher the prose specification of the algorithm and map it into pseudocode in a style similar to that used for CKY in the slides of 601.465. Please,\n",
    "as time is limited, only attempt this if you have finished the remainder of the assignment. Give the runtime of Eisner's algorithm\n",
    "\n",
    "**Answer:** $\\color{red}{\\text{FILL IN}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "b8229739-1653-407d-a3ec-f867c89f8bc3",
    "deletable": false
   },
   "source": [
    "Now, back to shift-reduce parsers. Shift-reduce parsers for\n",
    "constituency trace their heritage back to fundamental work on\n",
    "compilers in the 1960s; see Aho and Ullman (1972) for a\n",
    "history. However, the modern shift-reduce parser for dependency\n",
    "grammar is due to Nivre (2003). Shift-reduce parsers rely on a transition\n",
    "system, which we will take to be a quadruple $S = (C, T, c_s, C_t)$,\n",
    "following [Nivre 2013](http://stp.lingfil.uu.se/~nivre/master/transition.pdf).\n",
    "\n",
    "* $C$ is a set of \\textbf{configurations},\n",
    "* $T$ is a set of transitions, each of which is a (partial) function $t: C \\rightarrow C$,\n",
    "* $c_s$ is an initialization function, mapping a sentence $\\mathbf{x}$ to its initial configuration $c_s(\\mathbf{x})$, \n",
    "* $C_t \\subseteq C$ is a set of terminal configurations.\n",
    "\n",
    "A configuration $c$ for a sentence $\\mathbf{x}$ is a triple $c = \\left(\\sigma,\n",
    "\\beta, N \\right)$, where $\\sigma$ is termed the stack, $\\beta$ the\n",
    "buffer, and $N$ is a set of dependency arcs built so far. Note\n",
    "that dependency arcs are represented as an ordered pair $(i, j)$ that\n",
    "denotes a directed arc from the $i^\\text{th}$ word in $\\mathbf{x}$ towards\n",
    "the $j^\\text{th}$ word in $\\mathbf{x}$. \n",
    "\n",
    "A myriad transition systems abound, with a veritable cottage industry\n",
    "dedicated to the development of novel ones. In this work, we will\n",
    "focus on the so-called *arc-standard* system, which consists\n",
    "of the following definitions:\n",
    "\n",
    "\n",
    "* **Initialization:** $c_s(\\mathbf{x}) = ([0], [1, \\ldots, n]), \\emptyset)$\n",
    "* **Terminal:** $C_t = \\{c \\in C :  c = ([0], [0], N)  \\}$\n",
    "* **Transitions:** \\\\\n",
    "  * *Shift*: $(\\sigma, [i \\mid \\beta], N) \\Rightarrow ([\\sigma \\mid i], \\beta, N)$ \n",
    "  * *ReduceLeft:* $([\\sigma \\mid i \\mid j], \\beta, N) \\Rightarrow ([\\sigma \\mid j], \\beta, N \\cup \\{(j, i)\\})$ \n",
    "  * *ReduceRight: *$([\\sigma \\mid i \\mid j], \\beta, N) \\Rightarrow ([\\sigma \\mid i], \\beta, N \\cup \\{(i, j) \\})$\n",
    "  \n",
    "We have represented the transitions using the standard notation found\n",
    "in the dependency-parsing literature. To make it explicit, we will\n",
    "clarify a few points. We write $c \\Rightarrow c'$ to indicate that\n",
    "configuration $c \\in C$ transitions to the configuration $c' \\in C$.\n",
    "We write $[\\sigma | i]$ to indicate a stack whose top element is $i$\n",
    "and whose remaining elements are found in $\\sigma$. Similarly, we write\n",
    "$[i \\mid \\beta]$ to indicate a buffer whose first element is $i$ and the\n",
    "remaining elements are $\\beta$.\n",
    "\n",
    "**Important:* To gain a solid intuition for how the arc-standard transition system works, we ask that you view the animation present in the following [slides](http://demo.clab.cs.cmu.edu/fa2015-11711/images/b/b1/TbparsingSmallCorrection.pdf), due to [Miguel Ballesteros](http://miguelballesteros.com/).\n",
    "\n",
    "**Caveat:** Most dependency parsers also assign an arc label to the arc. We have omitted this for simplicity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "4943a52c-495b-4bc2-bc97-f834577b4493",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class ParsingTask(TaskSetting):\n",
    "    \"\"\"\n",
    "    xx = the sentence\n",
    "    aa = the parse tree (represented as the id of the parent where 0 is root)\n",
    "    yy = the shift/reduce actions that build the parse tree \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, false_pos_penalty=1):\n",
    "        super().__init__()\n",
    "        self.false_pos_penalty = false_pos_penalty    # lambda\n",
    "    \n",
    "    @classmethod\n",
    "    def convert_to_yy(cls, *, aa):\n",
    "        \"\"\"\n",
    "        Convert the aa sequence (the depedency tree of the parents) to the stack shift/reduce operations\n",
    "        \n",
    "        Returns a tuple representing the operations that convert this into a shift/reduce tree.\n",
    "             0 == shift operation\n",
    "             1 == reduce right\n",
    "             2 == reduce left\n",
    "        \"\"\"\n",
    "        stack = [(0, None)]\n",
    "        i = 0\n",
    "        # the stack actions that we have to perform\n",
    "        operations = []\n",
    "        while True:\n",
    "            if len(stack) >= 2 and stack[-2][0] == stack[-1][1] and stack[-1][0] not in aa[i:]:\n",
    "                # the top element of the stack is the child of the second on the top of the stack\n",
    "                operations.append(2)  # left\n",
    "                del stack[-1]\n",
    "            elif len(stack) >= 2 and stack[-2][1] == stack[-1][0]:\n",
    "                # the second element on the stack is the child of the item just added to the stack\n",
    "                operations.append(1)  # right\n",
    "                del stack[-2]\n",
    "            else:\n",
    "                # then we are going to perform a shift action\n",
    "                if i >= len(aa):\n",
    "                    break\n",
    "                operations.append(0)  # shift\n",
    "                id, parent = i + 1, aa[i]\n",
    "                i += 1\n",
    "                stack.append((id, parent))\n",
    "        assert len(stack) == 1 and stack[0][0] == 0\n",
    "        \n",
    "        # return a list of shift and\n",
    "        return tuple(operations)\n",
    "    \n",
    "    @classmethod\n",
    "    def convert_to_aa(cls, *, yy):\n",
    "        \"\"\"\n",
    "        Convert stack operations back to the depedency tree\n",
    "        \"\"\"\n",
    "        l = yy.count(0)  # count the number of words\n",
    "        assert l * 2 == len(yy)  # There should be exactly twice as many operations as words\n",
    "        aa = [-1] * l  # the list of parents\n",
    "\n",
    "        stack = [-1]\n",
    "        i = 0\n",
    "        for y in yy:\n",
    "            if y == 0:\n",
    "                # perform a shift operation by adding to the stack word i\n",
    "                stack.append(i)\n",
    "                i += 1\n",
    "            elif y == 1:\n",
    "                # perform shift right by marking the parent of the second element on the stack\n",
    "                # and removing it from the stack\n",
    "                aa[stack[-2]] = stack[-1] + 1\n",
    "                del stack[-2]\n",
    "            else:\n",
    "                # perform shift left\n",
    "                aa[stack[-1]] = stack[-2] + 1\n",
    "                del stack[-1]\n",
    "\n",
    "        assert len(stack) == 1, \"stack should only have the root element when it is done, otherwise this is invalid\"\n",
    "        \n",
    "        return tuple(aa)\n",
    "    \n",
    "    @classmethod\n",
    "    def iterate_data(cls, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Iterate through our parse data, converting the trees into a series of shift/reduce actions\n",
    "        That we can train and test on\n",
    "        \"\"\"\n",
    "        for example in iterate_trees(*args, **kwargs):\n",
    "            yield Data_type(\n",
    "                xx=example.xx,\n",
    "                oo=None,  # We are not dealing with partial observations in this homework\n",
    "                yy=cls.convert_to_yy(aa=example.aa)\n",
    "            )\n",
    "    \n",
    "    def reward(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        The proxy reward of prediction aa on this sentence if the true chunking is yy.\n",
    "        \"\"\"\n",
    "        aa_gen = self.convert_to_aa(yy=aa)\n",
    "        aa_gold = self.convert_to_aa(yy=yy)\n",
    "        \n",
    "        true_pos = sum(a == b for a,b in zip(aa_gen, aa_gold))\n",
    "        \n",
    "        exact = int(aa_gen == aa_gold)\n",
    "        return true_pos\n",
    "\n",
    "    def reward_F1_triple(self, *, aa, xx, yy):\n",
    "        \"\"\"\n",
    "        returns a triple (true_pos, true, pos) used to compute corpus-level F1: \n",
    "           `true_pos` is the number of \"true positives\" (chunks reported by `aa` that are truly in `yy`) \n",
    "           `true` is the number of chunks that are truly in `yy`  \n",
    "           `pos` is the number of chunks reported by `aa`\n",
    "        \"\"\"\n",
    "        # aa is the predicted output\n",
    "        # yy is the gold label from the dataset\n",
    "        # both have already been converted to the shift/reduce operations\n",
    "        # so we have to convert it back into a tree which lists the parents\n",
    "        aa_gen = self.convert_to_aa(yy=aa)\n",
    "        aa_gold = self.convert_to_aa(yy=yy)\n",
    "        \n",
    "        true_pos = sum(a == b for a,b in zip(aa_gen, aa_gold))\n",
    "        return np.array([len(aa_gold), len(aa_gen), true_pos])\n",
    "\n",
    "parsing_task = ParsingTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "903e5781-6f65-478c-8234-6dceda6ab4fe",
    "deletable": false
   },
   "source": [
    "Please study the following output carefully, to gain an intuition for why the above code converts\n",
    "dependency parses into sequences of shift and reduce actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "429718de-34e2-4683-9514-6a20666ad816",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(ParsingTask.convert_to_yy(aa=(0, 1, 1, 1, 7, 7, 1)))\n",
    "print(ParsingTask.convert_to_aa(yy=(0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 1, 1, 2, 2)))\n",
    "\n",
    "for aa in set(p.aa for p in iterate_trees('train')):\n",
    "    yy = ParsingTask.convert_to_yy(aa=aa)\n",
    "    aa2 = ParsingTask.convert_to_aa(yy=yy)\n",
    "    assert aa == aa2\n",
    "    assert len(yy) == len(aa)*2  # there will always be twice as many shift/reduce operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "1a6674e5-5c34-44cb-bae3-cace9960359d",
    "deletable": false
   },
   "source": [
    "The final bit of coding will involve the implementing the forward method of the `ParsingTransitionModel` below. [Dyet et al. (2015)](https://arxiv.org/abs/1505.08075) may be of some help to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "3c0b54c4-0dc6-461c-a980-8cf6f14b3315",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "class ParsingTransitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, task):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.task = task\n",
    "        self.backward_lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.forward_lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        \n",
    "        self.action_network_1 = nn.Linear(HIDDEN_SIZE*2+3, HIDDEN_SIZE)\n",
    "        self.action_network_2 = nn.Linear(HIDDEN_SIZE, 1)\n",
    "        \n",
    "        # network for combining two elements on the stack to make a new representation for this tree\n",
    "        self.combine_network_1 = nn.Linear(HIDDEN_SIZE*2, HIDDEN_SIZE*2)\n",
    "        self.combine_network_2 = nn.Linear(HIDDEN_SIZE*2, HIDDEN_SIZE)\n",
    "        \n",
    "        self.lstm_init_backwards = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "        self.lstm_init_forwards = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "        \n",
    "        self.stack_root = nn.Parameter(torch.rand(1, HIDDEN_SIZE))\n",
    "    \n",
    "    def initial_state(self, *, xx, xx_embedding):\n",
    "        \"\"\"\n",
    "        xx is going to be the result of the first encoding pass\n",
    "        and then we want to run the backwards LSTM over this xx sequence\n",
    "        \"\"\"\n",
    "        # this will represent the backwards LSTM over the words that are in the sentence\n",
    "        lookahead = []\n",
    "        \n",
    "        cx = self.lstm_init_backwards\n",
    "        hx = torch.tanh(cx)\n",
    "        lookahead.append(hx)\n",
    "        for i in range(xx_embedding.shape[1]-1,-1,-1):\n",
    "            hx, cx = self.backward_lstm(xx_embedding[:,i], (hx, cx))\n",
    "            lookahead.append(hx)\n",
    "        cx = self.lstm_init_forwards\n",
    "        hx = torch.tanh(cx)\n",
    "        # the pre root element on the stack\n",
    "        stack = [\n",
    "            (cx, hx, None),  # the -1 element doesn't need an embedding as this will \n",
    "        ]\n",
    "        \n",
    "        # push the root stack element\n",
    "        cx, hx = self.forward_lstm(self.stack_root, (hx, cx))\n",
    "        stack.append((cx, hx, self.stack_root))\n",
    "        \n",
    "        processed_tokens = 0\n",
    "        \n",
    "        # return a tuple\n",
    "        return lookahead, stack, processed_tokens\n",
    "        \n",
    "    def iterate_y(self, *, state, xx, yy_prefix):\n",
    "        lookahead, stack, processed_tokens = state\n",
    "        \n",
    "        if processed_tokens < len(xx):\n",
    "            # there are still tokens that this can process\n",
    "            # yield a shift operation\n",
    "            yield 0  # shift operation\n",
    "        if len(stack) > 2:\n",
    "            # these are the shift operations that we are allowed to perform\n",
    "            # if one of these are valid then both of these will valid\n",
    "            yield 1  # right\n",
    "            yield 2  # left\n",
    "    \n",
    "    def forward(self, *, state, xx, xx_embedding, yy_prefix, y):\n",
    "        ### STUDENTS START\n",
    "        raise NotImplementedError()  # REPLACE ME\n",
    "        ### STUDENTS END\n",
    "        return score, (lookahead, stack, processed_tokens)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "2b6253af-8fec-4f6b-9c9e-968ca09fc6b4",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "english_character_integerizer = Integerizer(tuple(set(w for d in iterate_trees('train') for w in ' '.join(d.xx))))\n",
    "parsing_model = ParsingTransitionModel(parsing_task)\n",
    "preprocess = CharacterLSTMPreprocessModule(english_character_integerizer)\n",
    "\n",
    "greedy_parse = LocallyNormalizedGreedyDecisionAgent(parsing_task, preprocess, parsing_model)\n",
    "\n",
    "greedy_trainer = PyTorchTrainer(\n",
    "    greedy_parse, \n",
    "    epochs=3, \n",
    "    evaluate=lambda x: x.test_F1(parsing_task.iterate_data('dev')))\n",
    "\n",
    "%time greedy_trainer.train(parsing_task.iterate_data('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "c998debe-42d6-43bc-bb8b-d2248d120287",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "beam_parser = BeamDecisionAgent(parsing_task, preprocess, parsing_model, beam_size=15)\n",
    "\n",
    "beam_trainer = PyTorchTrainer(\n",
    "    beam_parser,\n",
    "    epochs=3, \n",
    "    evaluate=lambda x: x.test_F1(parsing_task.iterate_data('dev')))\n",
    "    \n",
    "%time beam_trainer.train(islice(parsing_task.iterate_data('train'), 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "22a95910-72c2-44a2-b05c-20636769adba",
    "deletable": false
   },
   "source": [
    "## Speedups not covered in this assignment\n",
    "\n",
    "1. In making a neural model that you actually want to work with, you would probably want to spend some time thinking about how to perform mini-batching.  One of the main reasons that this will speed up our program, is that we are currently performing matrix-vector operations in most cases, in that there is only a single sentence that we are processing at a time.  When mini-batching, you are able to process more than once sentence at a time, this allows for using matrix-matrix operations which will be must faster.  Additionally, less time will be spent on the overhead of PyTorch/Python per sentence we are processing.  Making good use of a GPU will generally require that there are larger matrix-matrix operations which are being performed.\n",
    "\n",
    "2. Given that this network is *dynamically structured* based off the input of the yy sequence, it can sometimes be difficult to identify a good way to mini-batch multiple sentences at the same time.  An alternate approach is to distribute computation between a number of works that are each processing a single sentence at a time.  This allows us to take advantage of the fact that the sentences themselves are independent from each other while still being able to utilize resources.  [Pytorch multiprocessing documentation](http://pytorch.org/docs/master/notes/multiprocessing.html)\n",
    "\n",
    "3. You could also try changing the `num_threads` at the top of this notebook to experiment with the number of threads that are used for [BLAS](http://www.netlib.org/blas/) operations.  BLAS is the library that backs all of the matrix operations that you perform in virtually every other library or language (including R, numpy or matlab).  Assuming that you have *sufficiently large* matrices and have enough CPUs cores on your computer, increasing the number of threads that you are using can improve the runtime.\n",
    "\n",
    "\n",
    "If you want to try to improve the performance of the parser that we built in this notebook, you can try increasing the `HIDDEN_SIZE` that is used throughout.  We set it to 30 by default, but if you set it to larger value like 300, you should expect to see a significant improvement.  Note that the runtime performance scales $O(\\texttt{HIDDEN_SIZE}^2)$ so changing the value to 300 will make it take 100 times longer to train assuming that you don't apply any other techniques to speedup your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "g.cell_uuid": "ffaecb4f-01d2-4503-9f7e-b0a2aa29a55a",
    "deletable": false
   },
   "source": [
    "# The final test !!!\n",
    "\n",
    "Now that you have completed the assignment with the development datasets, try your models on the test dataset for 1 final time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d1b3293c-adeb-4195-8c00-1068bb66c801",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### iob_agent = ???\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "iob_agent.test_F1(iterate_data('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "g.cell_uuid": "d2e99359-4662-44d3-921b-81f859517388",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "### STUDENTS START\n",
    "### parse_agent = ???\n",
    "raise NotImplementedError()  # REPLACE ME\n",
    "### STUDENTS END\n",
    "\n",
    "parse_agent.test_F1(parsing_task.iterate_data('test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}